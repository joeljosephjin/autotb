cross_validation: False
Preprocessing...
Preparing input...
Input was already prepared
Use `python3 -m tensorboard.main --logdir=./logs/` to visualize accuracy and AUC graphs in real time
Training...
Loaded the numpy file dataset...
Diversity of Training Set: Class 0: 757 Class 1: 244
Diversity of Validation Set: Class 0: 194 Class 1: 57
Parameter number: 231602
Loading data set 0...
tcmalloc: large alloc 1587388416 bytes == 0x55e41094a000 @  0x7fb062bdf1e7 0x7fb06079f46e 0x7fb0607efc7b 0x7fb0607efd97 0x7fb0607effe9 0x7fb0607f2d7d 0x7fb0607f307b 0x7fb060894761 0x55e409701544 0x55e409701240 0x55e409775627 0x55e40976f9ee 0x55e409641eb0 0x7fb0607dcef7 0x55e409701437 0x55e409701240 0x55e409774973 0x55e40976f9ee 0x55e409702bda 0x55e409774d00 0x55e409702afa 0x55e409770915 0x55e40976f9ee 0x55e409702bda 0x55e409770915 0x55e40976f9ee 0x55e409702bda 0x55e409771737 0x55e40976f9ee 0x55e40976f6f3 0x55e4098394c2
WARNING:tensorflow:From /content/tbcnn/net.py:17: The name tf.keras.initializers.he_normal is deprecated. Please use tf.compat.v1.keras.initializers.he_normal instead.
/content/tbcnn/net.py:21: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).
  output = tf.layers.batch_normalization(output)
/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/normalization.py:455: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs, training=training)
/content/tbcnn/net.py:35: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).
  parallel = tf.layers.batch_normalization(parallel)
WARNING:tensorflow:From /content/tbcnn/net.py:98: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.
Instructions for updating:
The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.
WARNING:tensorflow:From /content/tbcnn/train_loop.py:46: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.
WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
WARNING:tensorflow:From /content/tbcnn/train_loop.py:51: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.
Traceback (most recent call last):
  File "train.py", line 52, in <module>
    train_variants.train_single(relPath('input'), epochs=epochs, size=SIZE)
  File "/content/tbcnn/train_variants.py", line 108, in train_single
    train_loop.train_net(training, test, size=size, epochs=epochs)
  File "/content/tbcnn/train_loop.py", line 115, in train_net
    next_training = create_dataloader(training_images_i, training_labels_i, size, batch_size)
  File "/content/tbcnn/train_loop.py", line 56, in create_dataloader
    return training_set_iterator.get_next()
UnboundLocalError: local variable 'training_set_iterator' referenced before assignment