cross_validation: False
Preprocessing...
Preparing input...
Input was already prepared
Use `python3 -m tensorboard.main --logdir=./logs/` to visualize accuracy and AUC graphs in real time
Training...
Loaded the numpy file dataset...
tcmalloc: large alloc 1587388416 bytes == 0x561e83172000 @  0x7f0fbec6e1e7 0x7f0fbc82e46e 0x7f0fbc87ec7b 0x7f0fbc87ed97 0x7f0fbc87efe9 0x7f0fbc881d7d 0x7f0fbc88207b 0x7f0fbc923761 0x561e7b3c8544 0x561e7b3c8240 0x561e7b43c627 0x561e7b4369ee 0x561e7b308eb0 0x7f0fbc86bef7 0x561e7b3c8437 0x561e7b3c8240 0x561e7b43b973 0x561e7b4369ee 0x561e7b3c9bda 0x561e7b43bd00 0x561e7b3c9afa 0x561e7b437915 0x561e7b4369ee 0x561e7b3c9bda 0x561e7b437915 0x561e7b4369ee 0x561e7b3c9bda 0x561e7b438737 0x561e7b4369ee 0x561e7b4366f3 0x561e7b5004c2
Diversity of Training Set: Class 0: 763 Class 1: 238
Diversity of Validation Set: Class 0: 188 Class 1: 63
WARNING:tensorflow:From /content/tbcnn/net.py:17: The name tf.keras.initializers.he_normal is deprecated. Please use tf.compat.v1.keras.initializers.he_normal instead.
/content/tbcnn/net.py:21: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).
  output = tf.layers.batch_normalization(output)
/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/normalization.py:455: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  return layer.apply(inputs, training=training)
/content/tbcnn/net.py:35: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).
  parallel = tf.layers.batch_normalization(parallel)
Parameter number: 231602
Loading data set 0...
WARNING:tensorflow:From /content/tbcnn/net.py:98: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.
Instructions for updating:
The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.
WARNING:tensorflow:From /content/tbcnn/train_loop.py:46: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.
WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
WARNING:tensorflow:From /content/tbcnn/train_loop.py:51: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.
Loaded data set 0...
























Loading data set 1...
Loaded data set 1...






















Loading data set 2...
Loaded data set 2...


